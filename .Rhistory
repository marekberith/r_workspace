summary(model)
summary(interaction_model)
model$coefficients
interaction_model$coefficients
#task 7
all_interaction_model <- cleaned_data %$%
lm(formula = wage_eur ~ (skill_dribbling + skill_curve + preferred_foot)^2)
summary(all_interaction_model)
summary(interaction_model)
#task 6
summary(model)
plot(cleaned_data$wage_eur, cleaned_data$skill_dribbling)
plot(cleaned_data$skill_dribbling, cleaned_data$wage_eur)
abline(model, col = "blue")
abline(interaction_model, col = "blue")
plot(cleaned_data$skill_dribbling, cleaned_data$wage_eur)
abline(interaction_model, col = "blue")
plot(cleaned_data$skill_dribbling, cleaned_data$wage_eur, cleaned_data$skill_curve)
plot(cleaned_data$skill_dribbling, cleaned_data$wage_eur)
abline(interaction_model, col = "blue")
abline(all_interaction_model, col = "blue")
plot(cleaned_data$skill_dribbling, cleaned_data$wage_eur)
abline(model, col = "blue")
abline(interaction_model, col = "red")
abline(all_interaction_model, col = "green")
abline(all_interaction_model, col = "green")
library('tidyverse')
library('tidymodels')
library('magrittr')
cric <- modeldata::crickets
model <- summary(lm(data = cric, formula = rate ~ temp + species))
model <- crickets %$% summary(lm(rate ~ temp + species))
model
broom::tidy(model)
#nefunguje?
broom::augment(model)
class(model)
library('ggfortify')
autoplot(model, which = c(1,2,5)) + theme_bw()
head(data)
class(data)
typeof(data)
cleaned_data <- data %>%
filter(player_positions == 'CM') %>%
pivot_wider(names_from = Skill, values_from = Value)
View(cleaned_data)
#task 2
model <- cleaned_data %$% lm(formula = wage_eur ~ skill_dribbling + skill_curve + preferred_foot)
summary(model)
#task 3 - check for heteroscedasticity
qqline(model$resid)
plot(model$resid ~ model$fitted.values)
plot(cooks.distance(model))
shapiro.test(model$resid)
boxplot(model$residuals)
#task 4
summary(model)
#task 5
cleaned_data
columns_to_plot <- c('skill_dribbling', 'skill_curve')
pairs(cleaned_data[, columns_to_plot])
#we need to use * instead of + to make model with interactions
interaction_model <- cleaned_data %$%
lm(formula = wage_eur ~ (skill_dribbling * skill_curve) + preferred_foot)
#task 6
summary(model)
summary(interaction_model)
model$coefficients
interaction_model$coefficients
#task 7
all_interaction_model <- cleaned_data %$%
lm(formula = wage_eur ~ (skill_dribbling + skill_curve + preferred_foot)^2)
summary(all_interaction_model)
plot(cleaned_data$skill_dribbling, cleaned_data$wage_eur)
abline(model, col = "blue")
abline(interaction_model, col = "red")
abline(all_interaction_model, col = "green")
plot(cleaned_data$skill_curve, cleaned_data$wage_eur)
abline(model, col = "blue")
abline(interaction_model, col = "red")
abline(all_interaction_model, col = "green")
cleaned_data <- data %>%
filter(player_positions == 'CM' && wage_eure < 50000) %>%
pivot_wider(names_from = Skill, values_from = Value)
cleaned_data <- data %>%
filter(player_positions == 'CM' && wage_eur < 50000) %>%
pivot_wider(names_from = Skill, values_from = Value)
cleaned_data <- data %>%
filter(player_positions == 'CM' & wage_eur < 50000) %>%
pivot_wider(names_from = Skill, values_from = Value)
View(cleaned_data)
#task 2
model <- cleaned_data %$% lm(formula = wage_eur ~ skill_dribbling + skill_curve + preferred_foot)
summary(model)
#task 3 - check for heteroscedasticity
qqline(model$resid)
plot(model$resid ~ model$fitted.values)
plot(cooks.distance(model))
shapiro.test(model$resid)
boxplot(model$residuals)
#task 4
summary(model)
#task 5
cleaned_data
columns_to_plot <- c('skill_dribbling', 'skill_curve')
pairs(cleaned_data[, columns_to_plot])
#we need to use * instead of + to make model with interactions
interaction_model <- cleaned_data %$%
lm(formula = wage_eur ~ (skill_dribbling * skill_curve) + preferred_foot)
#task 6
summary(model)
summary(interaction_model)
model$coefficients
interaction_model$coefficients
#task 7
all_interaction_model <- cleaned_data %$%
lm(formula = wage_eur ~ (skill_dribbling + skill_curve + preferred_foot)^2)
summary(all_interaction_model)
plot(cleaned_data$skill_curve, cleaned_data$wage_eur)
abline(model, col = "blue")
abline(interaction_model, col = "red")
abline(all_interaction_model, col = "green")
#task 1
data <- read.csv('data\\Practicum.4.2.csv')
head(data)
class(data)
typeof(data)
cleaned_data <- data %>%
filter(player_positions == 'CM') %>%
pivot_wider(names_from = Skill, values_from = Value)
View(cleaned_data)
#task 2
model <- cleaned_data %$% lm(formula = wage_eur ~ skill_dribbling + skill_curve + preferred_foot)
summary(model)
#task 3 - check for heteroscedasticity
qqline(model$resid)
plot(model$resid ~ model$fitted.values)
plot(cooks.distance(model))
shapiro.test(model$resid)
boxplot(model$residuals)
#task 4
summary(model)
#task 5
cleaned_data
columns_to_plot <- c('skill_dribbling', 'skill_curve')
pairs(cleaned_data[, columns_to_plot])
#we need to use * instead of + to make model with interactions
interaction_model <- cleaned_data %$%
lm(formula = wage_eur ~ (skill_dribbling * skill_curve) + preferred_foot)
#task 6
summary(model)
summary(interaction_model)
model$coefficients
interaction_model$coefficients
#task 7
all_interaction_model <- cleaned_data %$%
lm(formula = wage_eur ~ (skill_dribbling + skill_curve + preferred_foot)^2)
summary(all_interaction_model)
plot(cleaned_data$skill_curve, cleaned_data$wage_eur)
abline(model, col = "blue")
abline(interaction_model, col = "red")
abline(all_interaction_model, col = "green")
#task 8
poly_model <- cleaned_data %$%
lm(formula = wage_eur ~ poly(skill_dribbling))
summary(poly_model)
#task 8
poly_model <- cleaned_data %$%
lm(formula = wage_eur ~ poly(skill_dribbling, degree = 3))
summary(poly_model)
abline(poly_model, col = 'purple')
#task 8
poly_model <- cleaned_data %$%
lm(formula = wage_eur ~ poly(skill_dribbling, degree = 3))
# test
plot(cleaned_data$skill_dribbling, cleaned_data$wage_eur)
abline(model, col = "blue")
abline(interaction_model, col = "red")
abline(all_interaction_model, col = "green")
#task 8
poly_model <- cleaned_data %$%
lm(formula = wage_eur ~ poly(skill_dribbling, degree = 3))
summary(poly_model)
abline(poly_model, col = 'purple')
# test
plot(cleaned_data$skill_dribbling, cleaned_data$wage_eur)
abline(poly_model, col = 'purple')
degree_five_model <- cleaned_data %$%
lm(formula = wage_eur ~ poly(skill_dribbling, degree = 5))
summary(degree_five_model)
#task 9
res_sum_model <- sum(model$residuals)
res_sum_model
model$residuals
#task 9
res_sum_model <- sum(model$residuals^2)
res_sum_model
res_sum_five_model <- sum(degree_five_model$residuals^2)
res_sum_five_model
res_sum_three_model <- sum(poly_model$residuals^2)
res_sum_three_model
#task 10
library('ggplot2')
geom(poly_model)
geoms(poly_model)
#task 10
library('ggplot2')
library(tidyverse)
library(tidymodels)
library(magrittr)
tidymodels_prefer() # resolve package conflicts using tidy models methods
data(ames)
ames
View(ames)
ames <- ames %>% mutate(Sale_Price = log10(Sale_Price))
View(ames)
# stratified sampling, which is more complex than random sampling
set.seed(502)
ames_split <- initial_split(ames, prop = 0.8, strata = Sale_Price)
ames_train <- training(ames_split)
ames_test <- testing(ames_split)
tidymodels_prefer() # resolve package conflicts using tidy models methods
data(ames)
View(ames)
hist(ames$Sale_Price)
hist(x = ames$Sale_Price)
hist(x = ames$Sale_Price, freq = F)
hist(x = ames$Sale_Price, freq = F, breaks = 10)
hist(x = ames$Sale_Price, freq = F, breaks = 5)
hist(x = ames$Sale_Price, freq = F, breaks = 50)
# tasks
df <- read_csv('../data/Practicum.5.1.csv')
df
# tasks
df <- read.csv('../data/Practicum.5.1.csv')
# tasks
df <- read_csv('../data/Practicum.5.1.csv')
# tasks
df <- read_csv('/data/Practicum.5.1.csv')
# tasks
df <- read_csv('data/Practicum.5.1.csv')
df
hist(df$Sale_Price)
hist(df$Sale_Price, breaks = 100)
options(scipen=999)
hist(df$Sale_Price, breaks = 100)
View(df)
# task 2
df_grouped <- df %>%
group_by(id) %>%
summarise(Sale_Price = first(Sale_Price))
# task 2
df_grouped <- df %>%
group_by(ID) %>%
summarise(Sale_Price = first(Sale_Price))
df_grouped
# task 2
df_grouped <- df %>%
group_by(ID) %>%
summarise(Sale_Price = first(Sale_Price), SF_total = sum(Value_SF))
df_grouped
# task 2
df_grouped <- df %>%
group_by(ID, Sale_Price, Overall_Cond) %>%
summarise(SF_total = sum(Value_SF))
df_grouped
# task 3
pairs(df_grouped)
# task 2
df_grouped <- df %>%
group_by(ID, Sale_Price) %>%
summarise(SF_total = sum(Value_SF))
df_grouped
View(df)
# task 3
pairs(df_grouped)
View(df)
#' - neparove pre nezavisle merania
#' Testujeme hypotezu o rovnosti strednych hodnot, testy
#' treba vybrat podla toho, ci sa disperzie rovnaju alebo nerovnaju.
#' - test, ak disperzie sa rovnaju
#' - test, ak sa disperzie nerovnaju
#' Priklad 1
#' Dva druhy plastov (plastove okna) sme vystavili slnecnemu ziareniu
#' po dobu pol roka. Vysledky (odolnosti voci ziareniu v dnoch) sme
#' zaznamenali. Na hladine vyznamnosti $\alpha=0.05$. Testujte hypotezu o
#' rovnakej odolnosti voci slnecnemu ziareniu.
prvy <- c(85, 87, 92, 82, 84, 86)
druhy <- c(89, 89, 90, 84, 92)
#' Najprv grafy
boxplot(prvy, druhy, col = 'red')
#' Najprv grafy
boxplot(prvy, druhy, col = c('red', 'green'))
#' Test o rovnosti disperzii, pouzijeme Fisher Ratio test
var.test(prvy, druhy)
prvy <- c(85, 87, 92, 82, 80, 84, 86)
druhy <- c(89, 89, 90, 84, 92)
#' Najprv grafy
boxplot(prvy, druhy, col = c('red', 'green'))
#' Test o rovnosti disperzii, pouzijeme Fisher Ratio test
var.test(prvy, druhy)
prvy <- c(85, 87, 92, 80, 84, 86)
druhy <- c(89, 89, 90, 84, 92)
#' Najprv grafy
boxplot(prvy, druhy, col = c('red', 'green'))
#' Test o rovnosti disperzii, pouzijeme Fisher Ratio test
var.test(prvy, druhy)
var.test(prvy, druhy)$p.value
#' Kedze P hodnota = 0.59 > 0.05 nezamietam hypotezu o rovnosti
#' disperzii. Vyberieme spravny test rovnosti strednych hodnot
t.test(prvy, druhy)
#' Kedze P hodnota = 0.59 > 0.05 nezamietam hypotezu o rovnosti
#' disperzii. Vyberieme spravny test rovnosti strednych hodnot
t.test(prvy, druhy, paired = F)
#' Kedze P hodnota = 0.59 > 0.05 nezamietam hypotezu o rovnosti
#' disperzii. Vyberieme spravny test rovnosti strednych hodnot
t.test(prvy, druhy, paired = F, var.equal = T)
t.test(prvy, druhy, paired = F, var.equal = T)$p.value
#' P hodnota = 0.17 > 0.05, nezamietam hypotezu o rovnosti strednych hodnot,
#' odolnost voci ziareniu je rovnaka.
#####################################################
#' Priklad 2 - ked sa disperzie nebudu rovnat
#' Firma odobera ochranne pracovne prostriedky od dvoch dodavatelov
#' AA, BB. Zaznamenali sme dlzky dodavok na hladine vyznamnosti
#' $\alpha=0.05$ Testujte hypotezu o tom, ze dlzky dodavok su rovnake
aa <- c(10, 12, 15, 25, 18, 20, 15, 25, 30)
boxplot(aa, bb)
bb <- c(15, 15, 18, 10, 16, 12, 15)
boxplot(aa, bb)
boxplot(aa, bb, col = c('blue', 'purple'))
var.test(aa, bb)$p.value
#' Phodnota - 0.03 < 0.05, zamietam hypotezu o rovnosti disperzii
#' Teraz test pre rovnost strednych hodnot
t.test(aa, bb, paired = F, var.equal = F)
#' Phodnota - 0.03 < 0.05, zamietam hypotezu o rovnosti disperzii
#' Teraz test pre rovnost strednych hodnot
t.test(aa, bb, paired = F, var.equal = F)$p.value
#' Jednofaktorova analyza rozptylu (One Way ANOVA)
#' Datovy subor sa rozlozi do tried podla nejakeho faktora,
#' triedny faktor $\alpha_i$, mame napr. datovy subor mesacnych prijmov
#' 50 respondentov, rozdelime mesacne prijmy podla faktora typ vzdelania,
#' 1-svs, 2-sos, 3-vs
#' Testujeme potom hypotezu o nulovosti triedneho faktora, cize triedny
#' faktor nema vplyv na merania
#' ANOVA ma silne predpoklady
#' - normalita dat v triedach (Shapiro Wilk test)
#' - rovnost disperzii v triedach (Bartlettov test
#' triedny faktor $\alpha_i$, mame napr. datovy subor mesacnych prijmov
#' 50 respondentov, rozdelime mesacne prijmy podla faktora typ vzdelania,
#' 1-svs, 2-sos, 3-vs
#' Testujeme potom hypotezu o nulovosti triedneho faktora, cize triedny
#' faktor nema vplyv na merania
#' ANOVA ma silne predpoklady
#' - normalita dat v triedach (Shapiro Wilk test)
#' - rovnost disperzii v triedach (Bartlettov test)
#' Ak podmienky nie su splnene, tak musime testovat neparametrickym
#' testom (Kruskall Wallis)
library('readxl')
#' triedny faktor $\alpha_i$, mame napr. datovy subor mesacnych prijmov
#' 50 respondentov, rozdelime mesacne prijmy podla faktora typ vzdelania,
#' 1-svs, 2-sos, 3-vs
#' Testujeme potom hypotezu o nulovosti triedneho faktora, cize triedny
#' faktor nema vplyv na merania
#' ANOVA ma silne predpoklady
#' - normalita dat v triedach (Shapiro Wilk test)
#' - rovnost disperzii v triedach (Bartlettov test)
#' Ak podmienky nie su splnene, tak musime testovat neparametrickym
#' testom (Kruskall Wallis)
library(readxl)
library(RColorBrewer)
library(vioplot)
library(ggplot2)
library(ggpubr)
install.packages(ggpubr)
install.packages('ggpubr')
library(ggplot2)
library(ggpubr)
#' datovy subor dataE obsahuje, okrem ineho, data mesacny prijem a
#' informaciu o vzdelani respondenta (triedny faktor-vzdelanie, tri urovne).
#' Na hladine vyznamnosti $\alpha = 0.05$ testujte hypotezu, ze faktor
#' vzdelanie je nulovy a teda nema vplyv na vysku prijmu
data <- read_xlsx('data\dataE.xlsx')
#' datovy subor dataE obsahuje, okrem ineho, data mesacny prijem a
#' informaciu o vzdelani respondenta (triedny faktor-vzdelanie, tri urovne).
#' Na hladine vyznamnosti $\alpha = 0.05$ testujte hypotezu, ze faktor
#' vzdelanie je nulovy a teda nema vplyv na vysku prijmu
data <- read_xlsx('data\\dataE.xlsx')
data
#' najprv graficka analyza
boxplot(data$mprij~data$vzdelanie, col = brewer.pal(3, 'Pastel1'))
#' najprv graficka analyza
boxplot(data$mprij~data$vzdelanie, col = brewer.pal(3, 'Pastel1'),
main = 'Prijem podla vzdelania')
#' najprv graficka analyza
boxplot(data$mprij~data$vzdelanie, col = brewer.pal(3, 'Pastel1'),
main = 'Prijem podla vzdelania', xlab = 'vzdelanie',
ylab = 'prijem')
pomoc <- data.frame(data$vzdelanie, data$mprij)
ggline(pomoc)
ggline(pomoc, x = 'data$vzdelanie', y = 'data$mprij')
ggline(pomoc, x = 'data.vzdelanie', y = 'data$mprij')
ggline(pomoc, x = 'data.vzdelanie', y = 'data.mprij')
ggline(pomoc, x = 'data.vzdelanie', y = 'data.mprij',
add = c('mean_ci'))
ggline(pomoc, x = 'data.vzdelanie', y = 'data.mprij',
add = c('mean_ci', 'jitter', 'vioplot'))
ggline(pomoc, x = 'data.vzdelanie', y = 'data.mprij',
add = c('mean_ci', 'jitter', 'violin'))
ggline(pomoc, x = 'data.vzdelanie', y = 'data.mprij',
add = c('mean_ci', 'jitter', 'violin', 'boxplot'))
#' Overime podmienky ANOVA
#' Normalita dat v triedach
tapply(data$mprij, data$vzdelanie, shapiro.test)
#' Overime podmienky ANOVA
#' Normalita dat v triedach
tapply(data$mprij, data$vzdelanie, shapiro.test)$p.value
#' Overime podmienky ANOVA
#' Normalita dat v triedach
tapply(data$mprij, data$vzdelanie, shapiro.test)
#' Nulova hypoteza je, ze data su normalne rozdelene
#' P hodnoty pre kazdu triedu su > 0.05, teda nezamietam H0, data v triedach
#' su normalne rozdelene
#' Rovnost disperzii v triedach
bartlett.test(data$mprij~data$vzdelanie)
#' P hodnota > 0.05, nezamietam H0, disperzie v triedach su rovnake
#' Pred vypoctom musime este faktorizovat vzdelanie
#' H0 je, ze rovnost disperzii
#' P hodnota > 0.05, nezamietam H0, disperzie v triedach su rovnake
#' Pred vypoctom musime este faktorizovat vzdelanie
vzdelanie <- factor(data$vzdelanie)
an1 <- aov(data$mprij~vzdelanie)
an1
summary(an1)
ggline(pomoc, x = 'data.vzdelanie', y = 'data.mprij',
add = c('mean_ci', 'jitter', 'violin'))
#' P hodnota < 0.05 zamietam hypotezu o nulovosti faktora vzdelanie,
#' faktor je statisticky vyznamny a ma vplyv na mesacny prijem..
#' Nasleduju post testy, ktorymi urcime odlisnosti pre kazde dve triedy,
#' Tukey, Scheffe post test
TukeyHSD(an1)
#' trieda 1, 2 - phodnota > 0.05, nezamietam hypotezu o rovnosti strednych
#' hodnot, nie su odlisne
#' trueda 1, 3 a 2, 3 Phodnota < 0.05, zamietam hypotezu o rovnosti
#' strednych hodnot, triedy su odlisne
plot(TurkeyHSD(an1))
#' trieda 1, 2 - phodnota > 0.05, nezamietam hypotezu o rovnosti strednych
#' hodnot, nie su odlisne
#' trueda 1, 3 a 2, 3 Phodnota < 0.05, zamietam hypotezu o rovnosti
#' strednych hodnot, triedy su odlisne
plot(TukeyHSD(an1))
library(DescTools)
ScheffeTest(an1)
plot(ScheffeTest(an1))
#'Data  sa rozdeluju do tried podla dvoch faktorov, riadkovy je
#'oznaceny $\alpha_i$ a stlpcovy faktor $\beta_j$, napr. vysledky
#'liecby-vek, liek, merania-laborant, pristroj
#'Kazda trieda musi byt normalne rozdelena a s rovnakou disperziou,
#'nebudeme overovat, testuju sa teda dve hypotezy
#'H0 Riadkovy faktor je nulovy, nema vplyv na merania
#'H0 Stlpcovy faktor je nulovy, nema vplyv na merania
#'Priklad
#'Traja laboranti urobili dve opakovane merania latky deg na 4 chromatografoch.
#'Ma na vysledok vplyv laborant, pristroj?
anova1 <- read_xlsx('data//anova1.xlsx')
anova1
#' grafy rozdelit vzhladom na dva faktory
par(mfrow = c(1, 2))
boxplot(anova1$deg)
boxplot(anova1$deg~anova1$laborant)
boxplot(anova1$deg~anova1$laborant, brewer.pal(3, 'Pastel1'))
boxplot(anova1$deg~anova1$laborant, col = brewer.pal(3, 'Pastel1'))
boxplot(anova1$deg~anova1$pristroj, col = brewer.pal(4, 'Pastel1'))
#' grafy rozdelit vzhladom na dva faktory
par(mfrow = c(1, 2))
boxplot(anova1$deg~anova1$laborant, col = brewer.pal(3, 'Pastel1'))
boxplot(anova1$deg~anova1$pristroj, col = brewer.pal(4, 'Pastel1'))
pomoc1 <- data.frame(anova1$laborant, anova1$deg)
ggline(pomoc1, x = 'anova1.pristroj', y = 'anova1.deg',
add = c('mean_ci', 'jitter', 'violin'))
ggline(pomoc1, x = 'anova1.laborant', y = 'anova1.deg',
add = c('mean_ci', 'jitter', 'violin'))
ggline(pomoc1, x = 'anova1.pristroj', y = 'anova1.deg',
add = c('mean_ci', 'jitter', 'violin'))
anova1
ggline(pomoc1, x = 'anova1.laborant', y = 'anova1.deg',
add = c('mean_ci', 'jitter', 'violin'))
ggline(pomoc2, x = 'anova1.pristroj', y = 'anova1.deg',
add = c('mean_ci', 'jitter', 'violin'))
pomoc2 <- data.frame(anova1$pristroj, anova1$deg)
ggline(pomoc2, x = 'anova1.pristroj', y = 'anova1.deg',
add = c('mean_ci', 'jitter', 'violin'))
#' opat faktorizujeme
laborant <- factor(anova1$laborant)
pristroj <- factor(anova1$pristroj)
an2 <- aov(anova1$deg~laborant + pristroj)
summary(an2)
#' Obe P hodnoty < 0.05, zamietam hypotezu o nulovosti faktora
#' laborant, laborant ma vplyv na merania. Zamietam tiez
#' hypotezu o nulovosti faktora pristroj, pristroj ma vplyv na
#' vysledky merania. Nasleduju post testy
TukeyHSD(an2)
plot(TukeyHSD(an2))
#' Odlisnosti su vyznamne pre laborantov a, b a pre pristroje
#' A, D a C, D
#' ANOVA s interakciami, pribudne hypoteza H0 ze kombinacie faktorov
#' su nulove, nemaju vplyv na vysledky merania
an3 <- aov(anova1$deg~laborant + pristroj + laborant * pristroj)
summary(an3)
#' P hodnota pre interakcie > 0.05, interakcie nemaju vplyv na vysledky merani,
#' su nulove.
TukeyHSD(an3)
plot(TukeyHSD(an3))
