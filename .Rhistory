an2 <- aov(anova1$deg~laborant + pristroj)
summary(an2)
#' Obe P hodnoty < 0.05, zamietam hypotezu o nulovosti faktora
#' laborant, laborant ma vplyv na merania. Zamietam tiez
#' hypotezu o nulovosti faktora pristroj, pristroj ma vplyv na
#' vysledky merania. Nasleduju post testy
TukeyHSD(an2)
plot(TukeyHSD(an2))
#' Odlisnosti su vyznamne pre laborantov a, b a pre pristroje
#' A, D a C, D
#' ANOVA s interakciami, pribudne hypoteza H0 ze kombinacie faktorov
#' su nulove, nemaju vplyv na vysledky merania
an3 <- aov(anova1$deg~laborant + pristroj + laborant * pristroj)
summary(an3)
#' P hodnota pre interakcie > 0.05, interakcie nemaju vplyv na vysledky merani,
#' su nulove.
TukeyHSD(an3)
plot(TukeyHSD(an3))
#task 1
data <- read.csv('data\\Practicum.4.2.csv')
library('tidyverse')
library('tidymodels')
library('magrittr')
cric <- modeldata::crickets
model <- summary(lm(data = cric, formula = rate ~ temp + species))
model <- crickets %$% summary(lm(rate ~ temp + species))
model
broom::tidy(model)
#nefunguje?
broom::augment(model)
autoplot(model, which = c(1,2,5)) + theme_bw()
summary(model)
#task 1
data <- read.csv('data\\Practicum.4.2.csv')
#nefunguje?
broom::augment(model)
broom::tidy(model)
#nefunguje?
broom::augment(model)
# task 3
pairs(df_grouped)
library(tidyverse)
library(tidymodels)
library(magrittr)
options(scipen=999)
tidymodels_prefer() # resolve package conflicts using tidy models methods
data(ames)
View(ames)
hist(x = ames$Sale_Price, freq = F, breaks = 50)
ames <- ames %>% mutate(Sale_Price = log10(Sale_Price))
# stratified sampling, which is more complex than random sampling
set.seed(502)
ames_split <- initial_split(ames, prop = 0.8, strata = Sale_Price)
ames_train <- training(ames_split)
ames_test <- testing(ames_split)
# tasks
# task 1
df <- read_csv('data/Practicum.5.1.csv')
hist(df$Sale_Price, breaks = 100)
# task 2
df_grouped <- df %>%
group_by(ID, Sale_Price) %>%
summarise(SF_total = sum(Value_SF))
df_grouped
View(df)
# task 3
pairs(df_grouped)
df_grouped
# task 4
library(rsample)
folds <- vfold_cv(df_grouped, v = 5)
folds <- vfold_cv(df_grouped, v = 5)
# task 4
library(rsample)
folds <- vfold_cv(df_grouped, v = 5)
training_data <- training(folds)
testing_data <- testing(folds)
print(folds)
is.data.frame(df_grouped)
data <- read.csv('data/Default.csv')
data
data[data$default == 'Yes']
data[data$default = 'Yes']
data[data$default]
data[default =='Yes']
data[data$default == 'Yes',]
data[data$default == 'Yes',]$default = 0
data
data <- read.csv('data/Default.csv')
data
data[data$default == 'Yes',]$default = 1
data[data$default == 'No',]$default = 0
data[data$student == 'Yes',]$default = 1
data[data$student == 'No',]$default = 0
data
data <- read.csv('data/Default.csv')
data
data[data$default == 'Yes',]$default = 1
data[data$default == 'No',]$default = 0
data[data$student == 'Yes',]$student = 1
data[data$student == 'No',]$student = 0
data
library(tidymodels)
library(tidyverse)
library(magrittr)
library(tidymodels)
library(tidyverse)
library(magrittr)
data <- read.csv('data/Default.csv')
data
# Task 1
# binary encode
data[data$default == 'Yes',]$default <- 1
data[data$default == 'No',]$default <- 0
data[data$student == 'Yes',]$student <- 1
data[data$student == 'No',]$student <- 0
data
# add IDs
data$ID <-
1:5
data
1:nrow(data)
data
# add IDs
data$ID <- 1:nrow(data)
data
# Task 2
hist(data)
# Task 2
hist(data$balance)
hist(data$income)
qqplot(data$balance)
qqplot(y = data$balance)
qqplot(data$balance, data$student)
qqplot(data$balance, data$default)
qqplot(data$balance, data$student)
qqplot(data$balance, data$default)
qqplot(data$income, data$default)
qqplot(data$income, data$student)
qqplot(data$balance, data$default)
hist(data$income)
lines(density(data), col = "red")
lines(density(data$income), col = "red")
lines(density(x), col = 4, lwd = 2)
lines(density(data$income), col = 4, lwd = 2)
lines(density(data$income))
hist(data$income)
lines(density(data$income))
lines(density(data$income), bw = 0.1)
lines(density(data$income, bw = 0.1))
hist(data$income)
lines(density(data$income, bw = 0.1))
hist(data$income)
lines(density(data$income, bw = 0.1))
lines(density(data$income, bw = 0.01))
lines(density(data$income, bw = 0.001))
lines(density(data$income, bw = 1))
hist(data$income, density(data$income))
library(tidymodels)
library(tidyverse)
library(magrittr)
data <- read.csv('data/Default.csv')
data
# Task 1
# binary encode
data[data$default == 'Yes',]$default <- 1
data[data$default == 'No',]$default <- 0
data[data$student == 'Yes',]$student <- 1
data[data$student == 'No',]$student <- 0
data
# add IDs
data$ID <- 1:nrow(data)
data
hist(data$income, density(data$income))
# Task 2
hist(data$income, freq = FALSE, main = "Histogram with KDE Line", xlab = "Income")
lines(density(data$income), col = "red")
# Task 2
hist(data$income, main = "Histogram with KDE Line", xlab = "Income")
lines(density(data$income), col = "red")
lines(density(data$income))
# Task 2
hist(data$income, freq = F)
lines(density(data$income))
# Task 2
hist(data$balance, freq = F)
lines(density(data$balance))
lines(density(data$balance), col = 'blue')
lines(density(data$balance, bw = 0.1), col = 'blue')
# Task 2
hist(data$balance, freq = F)
lines(density(data$balance, bw = 0.1), col = 'blue')
lines(density(data$balance, bw = 1), col = 'blue')
lines(density(data$balance, bw = 100), col = 'blue')
lines(density(data$balance, bw = 1000), col = 'blue')
lines(density(data$balance, bw = 200), col = 'blue')
# Task 2
hist(data$balance, freq = F)
lines(density(data$balance, bw = 200), col = 'blue')
lines(density(data$balance, bw = 150), col = 'blue')
lines(density(data$balance, bw = 100), col = 'blue')
lines(density(data$balance, bw = 900), col = 'blue')
lines(density(data$balance, bw = 50), col = 'blue')
lines(density(data$balance, bw = 120), col = 'blue')
# Task 2
hist(data$balance, freq = F)
lines(density(data$balance, bw = 120), col = 'blue')
# Task 2
hist(data$balance, freq = F)
lines(density(data$balance, bw = 150), col = 'blue')
# Task 2
hist(data$balance, freq = F, breaks = 200)
# Task 2
hist(data$balance, freq = F, breaks = 500)
# Task 2
hist(data$balance, freq = F, breaks = 10)
# Task 2
hist(data$balance, freq = F, breaks = 50)
lines(density(data$balance, bw = 150), col = 'blue')
qqplot(data$balance, data$default)
# converting to binary variables to factors
data %<>% mutate(default = as_factor(default))
qqplot(data$balance, data$default)
data
data$default
qqplot(data$balance[data$default == 0], data$default)
qqplot(data$balance[data$default == 1], data$default)
qqnorm(data$balance[data$default == 1], data$default)
qqnorm(data$balance[data$default == 1])
qqnorm(data$balance)
# normal q-q plot
qqnorm(data$balance)
# normal q-q plot
qqnorm(data$balance)
lines(density(data$balance, bw = 150), col = 'blue')
qqline()
qqline(data$balance)
# normal q-q plot
qqnorm(data$balance)
# normal q-q plot
qqnorm(data$balance)
qqline(data$balance)
qqline(data$balance, col = 'blue')
# q-q plot
qqplot(data$balance[data$default == 1], data$default)
# q-q plot
qqplot(data$balance[data$default == 1], data$default)
# Task 2
# histogram
hist(data$balance, freq = F, breaks = 50)
lines(density(data$balance, bw = 150), col = 'blue')
# remove with 0 on balance
data <- data[data$balance != 0]
# Task 2
# histogram
hist(data$balance, freq = F, breaks = 50)
# remove with 0 on balance
data <- data[data$balance != 0,]
# Task 2
# histogram
hist(data$balance, freq = F, breaks = 50)
lines(density(data$balance, bw = 150), col = 'blue')
# q-q plot
qqplot(data$balance[data$default == 1], data$default)
# q-q plot
qqplot(data$balance[data$default == 1], data$default)
# q-q plot
qqplot(data$balance, data$default)
# q-q plot
qqplot(data$balance, data$default)
library(tidymodels)
library(tidyverse)
library(magrittr)
data <- read.csv('data/Default.csv')
data
# Task 1
# binary encode
data[data$default == 'Yes',]$default <- 1
data[data$default == 'No',]$default <- 0
data[data$student == 'Yes',]$student <- 1
data[data$student == 'No',]$student <- 0
data
# add IDs
data$ID <- 1:nrow(data)
data
# converting to binary variables to factors
data %<>% mutate(default = as_factor(default))
data %<>% mutate(student = as_factor(student))
# remove with 0 on balance
data <- data[data$balance != 0,]
# Task 2
# histogram
hist(data$balance[data$default == 0, ], freq = F, breaks = 50)
# Task 2
# histogram
hist(data$balance[data$default == 0, ], freq = F, breaks = 50)
# Task 2
# histogram
hist(data$balance[data$default == 0, ], freq = F, breaks = 50)
# Task 2
# histogram
hist(data$balance, freq = F, breaks = 50)
# Task 2
# histogram
hist(data[data$default == 0, ]$balance, freq = F, breaks = 50)
# Task 2
# histogram
hist(data[data$default == 0]$balance, freq = F, breaks = 50)
# Task 2
# histogram
hist(data[data$default == 0, ]$balance, freq = F, breaks = 50)
library(tidymodels)
library(tidyverse)
library(magrittr)
data <- read.csv('data/Default.csv')
data
# Task 1
# binary encode
data[data$default == 'Yes',]$default <- 1
data[data$default == 'No',]$default <- 0
data[data$student == 'Yes',]$student <- 1
data[data$student == 'No',]$student <- 0
data
# add IDs
data$ID <- 1:nrow(data)
data
# converting to binary variables to factors
data %<>% mutate(default = as_factor(default))
data %<>% mutate(student = as_factor(student))
# remove with 0 on balance
data <- data[data$balance != 0,]
# Task 2
# histogram
hist(data[data$default == 0, ]$balance, freq = F, breaks = 50)
lines(density(data[data$default == 0, ]$balance, bw = 150), col = 'blue')
# normal q-q plot
qqnorm(data[data$default == 0, ]$balance)
qqline(data[data$default == 0, ]$balance, col = 'blue')
# q-q plot
qqplot(data$balance[data$default == 0, ], data$default)
# q-q plot
qqplot(data[data$default == 0, ]$balance, data$default)
library('latexpdf')
#'# Neparametricke metody
#'neparametricke metody pouzivame tam, kde data nie su normalne
#'rozdelene, je ich malo, su nestandardne. Neparametricke testy
#'vyzaduju podmienku, ze data su z nejakeho spojiteho rozdelenia.
#'Su menej presne a menej citlive.
#'
#'Hypoteza H0 je v tvare
#'$H_0\quad \text{data su nahodne}\quad H_1\quad \text{nie su nahodne}$
#'Test serii (Wald Wofovitzov test), testujeme nahodnost dat.
#'Test je citlivy na trend, kniznica randtests
library(randtests)
install.packages('randtests')
#'# Neparametricke metody
#'neparametricke metody pouzivame tam, kde data nie su normalne
#'rozdelene, je ich malo, su nestandardne. Neparametricke testy
#'vyzaduju podmienku, ze data su z nejakeho spojiteho rozdelenia.
#'Su menej presne a menej citlive.
#'
#'Hypoteza H0 je v tvare
#'$H_0\quad \text{data su nahodne}\quad H_1\quad \text{nie su nahodne}$
#'Test serii (Wald Wofovitzov test), testujeme nahodnost dat.
#'Test je citlivy na trend, kniznica randtests
library(randtests)
v<- c(7.7, 7.8, 8.5, 7.8, 7.9, 9, 7.5, 8.2, 9.3, 8.1)
runs.test(v, plot=T)
#' Phodnota > 0.05, data su nahodne
runs.test(v, alternative = 'left.sided')
runs.test(v, alternative = 'right.sided')
#' Test kritickych bodov, bodov obratu (turning point test)
#' odhaluje periodicitu v datach
turning.point.test(v)
#' P hodnota > 0.05, nezamietam hypotezu o nahodnosti dat
turning.point.test(v, alternative = 'left.sided')
#'sme testovali tvrdenia o strednej hodnote, boli jednovyberove t.testy
#'a dvojvyberove t.testy - parove testy a neparove
#'# Znamienkovy test (sign test)
#'testujeme $H_0\quad \text{median} = x_0\quad H_1\quad
#'\text{median}\neq x_0$
#'Jedina podmienka kladena na data je, aby boli vyberom zo
#'spojiteho rozdelenia. Test ma malu silu, t.j. chyba druheho druhu
#'je velka (nezamietame H0 a pritom H0 neplati).
#'Testujte, ze data z predosleho prikladu maju median = 8, teda ze
#'priemerna rychlost ani po uprave sa nezmenila.
boxplot(v, horizontal = T)
hist(v)
#' pre symetricke data je sikmost nulova, spocitame este sikmost
library(moments)
skewness(v)
library(BSDA)
install.packages('BSDA')
library('BSDA')
library('BSDA')
install.packages('BSDA')
install.packages("BSDA")
library('BSDA')
SIGN.test(v, md=8)
#' P hodnota > 0.05 nezamietame hypotezu o tom, ze priemerna
#' rychlost sa nezmenila. Tento test mozeme pouzit aj
#' ako dvojvyberovy parovy. Testujeme, ze median rozdielov je rovny
#' nejakemu cislu, pouzijeme ho tam, kde je asymetria dat.
#' Ak pridame predpoklad, ze data su symetricke okolo medianu, tak
#' radsej pouzijem jednovyberovy Wilcoxonov test
#' -signed rank test. Otestujeme nase data, ci su symetricke a ak ano
#' testujeme tymto testom.
library(lawstat)
install.packages('lawstat')
#' P hodnota > 0.05 nezamietame hypotezu o tom, ze priemerna
#' rychlost sa nezmenila. Tento test mozeme pouzit aj
#' ako dvojvyberovy parovy. Testujeme, ze median rozdielov je rovny
#' nejakemu cislu, pouzijeme ho tam, kde je asymetria dat.
#' Ak pridame predpoklad, ze data su symetricke okolo medianu, tak
#' radsej pouzijem jednovyberovy Wilcoxonov test
#' -signed rank test. Otestujeme nase data, ci su symetricke a ak ano
#' testujeme tymto testom.
library(lawstat)
symmetry.test(v)
#' p hodnota >0.05, rad
wilcox.test(v)
#' p hodnota >0.05, radsej Wilcoxonov test
wilcox.test(v, mu=8)
#' P hodnota >0.05, nezamietam H0, priemerna rychlost sa nezmenila
#' Pri tradicnom opracovani suciastok sa dosahovali priemerne hodnoty
#' kvalitativnej vlastnosti 4.4, pokusne sa zavadza nova jednoduchsia
#' metoda opracovania suciastok. Hodnoty kvalitativnej vlastnosti su
#' v datovom subore x.
x<-c(4.5, 4.3, 4.1, 4.9, 4.6, 3.6, 4.7, 5.1, 4.8, 4, 3.7, 4.4,
4.9, 4.9, 5.2, 5.1, 4.7, 4.9, 4.6, 4.8)
boxplot(x)
symmetry.test(x)
#' Data su symetricke, teda jednoznacne WT.
wilcox.test(x, mu=4.4)
#' P hodnota>0.05, nezamietam hypotezu, ze novou metodou opracovane
#' suciastky maju rovnaku kvalitativnu vlastnost
#' Prakticky by sme mali na zaciatku overit normalitu dat a ak
#' su normalne rozdelene, tak t.test
library(nortest)
shapiro.test(x)
t.test(x, mu=4.4)
shapiro.test(x) #normalita
t.test(x, mu=4.4)
pred <- c(87,61,98,90,93,74,83,72,81,75,83)
po <- c(50,45,79,90,88,65,52,79,84,61,52)
#' Aj parametrickym testom nam vyslo, ze kvalitativna vlastnost ostala rovnaka.
#' Priklad pouzitia, ako parovy test.
#' Su dane casy v sekundach, pocas ktorych vyriesili kontrolne ulohy
#' ziaci pred a po specialnych cviceniach z pamatoveho pocitania. Zlepsili
#' cvicenia schopnost ziakov rychlejsie riesit ulohy?
#' Ak sa pytame, ci zlepsili, pred - po >= 0, teda negacia je <0 alternativa
#' bude less. Testy vyberam podla toho, ci rozdiely su alebo nie su
#' symetricke.
pred <- c(87,61,98,90,93,74,83,72,81,75,83)
po <- c(50,45,79,90,88,65,52,79,84,61,52)
rozdiel = pred - po
rozdiel
boxplot(rozdiel, horizontal = T)
boxplot(rozdiel, horizon)
boxplot(rozdiel, horizontal = T)
skewness(rozdiel)
symmetry.test(rozdiel)
wilcox.test(rozdiel, alternative = 'less')
#' Dvojvyberovy neparovy test, neparametricky, dvojvyberovy
#' Wilcoxonov test (Mann Whitney U test). Nulova hypoteza je
#' $H_0\quad F_X=F_Y$. Pred testom treba overit, ci sa rozdelenia aspon
#' priblizne rovnaju a tiez ci maju rovnaku disperziu. Ak su velke rozdiely,
#' tak dvojvyberovy Kolmogorov Smirnov test. Neparametricky test pre
#' rovnost disperzii Levene test, kniznica BSDA
#' Z produkcie dvoch firiem bolo nahodne vybratych n=10 a m=8 vyrobkov.
#' Nezavisli experti hodnotili ich kvalitu pridelenim bodov.
#' Datovy subor x, y. Testujte hypotezu, ze kvalita vyrobkov dvoch
#' firiem je rovnaka.
x<-c(420,560,600,490,550,570,340,480,510,460)
y<-c(400,420,580,470,470,500,520,530)
boxplot(x, y, col = c('blue', 'red'))
par(mfrow=c(1,2))
hist(x, breaks = 5)
hist(y, breaks = 5)
par(mfrow = c(1,1))
#' Uprava dat pre test
data <- data.frame('body' = c(x, y), 'firma' = rep(c(1,2), times = c(10,8)))
data
levene.test(data$body, data$firma)
#' Mozeme pouzit dvojvyberovy WT
wilcox.test(x,y)
#' P hodnota > 0.05, nezamietame hypotezu o rovnosti DF, teda aj
#' medianov, kvalita je rovnaka, este KS test
ks.test(x, y)
#' plati tvrdenie hore
#'# Kruskal Wallisov test, neparametricky ekvivalent k ANOVA. ANOVA
#'mala silne podmienky, normalita dat v triedach, rovnost disperzii.
#'Ak to nie je splnene, tak KW test. Pri ANOVE sme testovali,
#'ze stredne hodnoty sa rovnaju, tu testujeme, ze distribucne funkcie sa
#'rovnaju (a teda aj mediany). Zaznamenali sme vykony strojov troch znaciek.
#'Na hladine vyznamnosti $\alpha=0.05$ testujte hypotezu vykony strojov
#'su rovnake.
data<-data.frame("vykon"=c(53,47,46,61,55,52,58,54,51,51,49,54),
"stroj"=c(rep(1,3),rep(2,5),rep(3,4)))
boxplot(data$vykon~data$stroj)
boxplot(data$vykon~data$stroj, col=c('red', 'green', 'blue'))
#' Faktorizujeme
data$stroj <- factor(data$stroj)
data$stroj
kruskal.test(data$vykon, data$stroj)
#' P hodnota <0.05, zamietame hypotezu o rovnakej vykonnosti
#' Nasleduju post testy. ANOVA (Tukey, Scheffe), tu pouzijeme dunn.test
#' (aj kniznica sa tak vola)
library('dunn.test')
dunn.test(data$vykon, data$stroj)
dunn.test(data$vykon, data$stroj, altp = T)
dunn.test(data$vykon, data$stroj, altp = T, list = T)
